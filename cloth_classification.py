# -*- coding: utf-8 -*-
"""cloth-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xe_sQHrJOcvr48ZiWsVT9-gxGlWM9oSB
"""

#################################################################################################################################
################################################   딥러닝  22.11.14 : 1주차 code ################################################
#################################################################################################################################

import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical # 원합인코딩()
from tensorflow.keras.layers import Dense, Flatten # 히든 레이터 한단을 만들기위해 /
from tensorflow.keras.models import Sequential # 차례대로 모형을 쌓겠다

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()

x_train[0].shape

# label 이름을 저장
# 딕셔너리의 형태로 저장 {key:value}
item = {
      0: 'T-shirt/top'
    , 1: 'Trouser'
    , 2: 'Pullover'
    , 3: 'Dress'
    , 4: 'Coat'
    , 5: 'Sandal'
    , 6: 'Shirt'
    , 7: 'Sneaker'
    , 8: 'Bag'
    , 9: 'Ankle boot'
}

# 데이터 포멧 확인
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# train 이미지 확인
plt.figure(figsize=(8,8))
for i in range(16):
  plt.subplot(4,4, i+1) # plt.subplot(row,column,index) == par(mfrow=c(4,4))
  plt.suptitle("Train Images", fontsize=20) # 하나의 큰 제목
  plt.title(item[y_train[i]])
  plt.imshow(x_train[i], cmap=plt.cm.gray)
  plt.axis('off')

plt.show()

# test 이미지 확인
plt.figure(figsize=(8,8))
for i in range(16):
  plt.subplot(4,4, i+1) # plt.subplot(row,column,index) == par(mfrow=c(4,4))
  plt.suptitle("Test Images", fontsize=20) # 하나의 큰 제목
  plt.title(item[y_test[i]])
  plt.imshow(x_test[i], cmap=plt.cm.gray)
  plt.axis('off')

plt.show()

## 전처리 ##
# 이미지 데이터 전처리

x_train = x_train.astype('float32') # datatype을 float32로 변경(GPU로 사용하기 위해서는 32bit)
x_train = x_train/255 # normalization

## 스케일링 : 시작점을 잘 찾기 위해서, (0,1) 또는 (-1,1)

x_train = x_test.astype('float32')
x_test = x_test/255

y_onehot_train = to_categorical(y_train, num_classes= 10) # one-hot encoding을 통해 10개의 레이블이 0,1 로 표현
y_onehot_test = to_categorical(y_test, num_classes = 10)

y_onehot_train[0]

# 전처리 결과
for i in [x_train, y_onehot_train, x_test, y_onehot_test]:
  print(i.shape)

##  keras 를 활용한 모델 생성 ##
OUTPUT_SHAPE = 10 # 출력 데이텉가 나오는 포맷
BATCH_SIZE = 128 # 한 번에 처리할 데이터량 설정
EPOCHS = 10 # 신경망을 학습할 횟수
VERBOSE = 1 # 학습진행상황 출력모드(기본값=1)

model = Sequential([ # 모델을 한층한층 쌓아라
    Flatten(), # 데이터를 벡터의 형태로 바꿈(즉 현재 28x28matrix를 벡터로 바꾸어야 한다)
    Dense(128,activation='relu'),  # 128개 노드마다 렐루 활성함수
    Dense(64,activation='relu'),
    Dense(10,activation='softmax') # y를 예측한다. 
])



## 신경망 모델 컴파일
# : 어떠한 목적함수수사용하고, 목적함수를 최적화 할 때 사용될 최적화알고리즘 선택, 모형의 성능의 상황 모니터링은 어느것으러?

model.compile(
    optimizer = 'adam',
    loss='categorical_crossentropy', 
    metrics=['accuracy']
)

## 컴파일 이란?? :주어진 language로 작성된 컴퓨터 프로그램을 다른 언어의 동등한 프로그램으로 변환하는 프로세스

history = model.fit(
    x_train, y_onehot_train,
    epochs = EPOCHS,
    batch_size = BATCH_SIZE,
    verbose = VERBOSE,
    validation_split=0.3
)

# 2.11초, 로스값 22.277 정확도 0.0991 -> 로스값이 점점 작아지는 방향으로 작동동

## 결과확인

plt.figure(figsize=(14,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label="Validation Accurary")
plt.legend(loc='lower right')
plt.title("Training and Validation Accurary")

plt.subplot(1,2,2)
plt.plot(history.history['loss'],label="Training Loss")
plt.plot(history.history['val_loss'],label="Validation Loss")
plt.legend(loc='upper right')
plt.title("Training and Validation Loss")

plt.show()

history.history

## 신경망 모델 평가

# 테스트 데이터를 이용한 평가

model.evaluate(x_test, y_onehot_test)

y_pred_enc = model.predict(x_test)
y_pred_enc[0:5]

y_pred=[np.argmax(i) for i in y_pred_enc]

y_pred[0:10]

fig, ax = plt.subplots(figsize=(8,8))
for idx, row in enumerate(x_test[:16]) :
  plt.subplot(4,4,idx+1)
  img = row.reshape(28,28)
  fig.suptitle("Predicted values", fontsize=20)
  plt.axis('off')
  plt.imshow(img,cmap=plt.cm.gray)

## 혼동행렬 = 오차행렬

matrix = confusion_matrix(y_test, y_pred)
df = pd.DataFrame(matrix)
df.colums = item.values()
df.index = item.values()
df

